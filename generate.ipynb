{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "WEIGHTS_DIR = \"creepy_pasta_weights/\"\n",
    "with open(WEIGHTS_DIR+\"itos.pkl\",'rb') as f:\n",
    "    itos=pickle.load(f)\n",
    "with open(WEIGHTS_DIR+\"stoi.pkl\",'rb') as f:\n",
    "    stoi=pickle.load(f)\n",
    "generator_state_dict = torch.load(WEIGHTS_DIR+\"generator.weights\")\n",
    "    \n",
    "vocab_size = len(itos)\n",
    "embedding_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn0 = nn.LSTM(400, 1150, 1)\n",
    "\n",
    "rnn1 = nn.LSTM(1150, 1150, 1)\n",
    "\n",
    "rnn2 = nn.LSTM(1150, 400, 1)\n",
    "\n",
    "rnns = nn.ModuleList([rnn0,rnn1,rnn2])\n",
    "\n",
    "embedder= nn.Embedding(vocab_size,embedding_size)\n",
    "decoder = nn.Linear(embedding_size,vocab_size,bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LangModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, embedder, rnns, decoder):\n",
    "        super(LangModel, self).__init__()\n",
    "        self.embedder = embedder\n",
    "        self.rnns = rnns\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self,input):\n",
    "        out=embedder(input)\n",
    "        for rnn in rnns:\n",
    "            out,hid = rnn(out)\n",
    "        out = decoder(out[:,-1])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LangModel(embedder,rnns,decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(generator_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LangModel(\n",
       "  (embedder): Embedding(257874, 400)\n",
       "  (rnns): ModuleList(\n",
       "    (0): LSTM(400, 1150)\n",
       "    (1): LSTM(1150, 1150)\n",
       "    (2): LSTM(1150, 400)\n",
       "  )\n",
       "  (decoder): Linear(in_features=400, out_features=257874, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))\n",
    "def generate(length,creativity,dist=False):\n",
    "    next_word = \".\"\n",
    "    text = \"\"\n",
    "    for i in range (length):\n",
    "        tensor_output = model(torch.tensor([[stoi[next_word]]],dtype=torch.long,device=\"cuda\"))[0]\n",
    "        output = (tensor_output).detach().cpu().numpy()\n",
    "        \n",
    "#hard cutoff\n",
    "#         subdist = softmax(np.sort(output)[-creativity:])\n",
    "#         print (subdist)\n",
    "#         next_word = itos2[np.random.choice(np.argsort(output)[-creativity:],p=subdist)]\n",
    "\n",
    "#soft cutoff\n",
    "        distribution = softmax(output/creativity)\n",
    "        ranks = np.argsort(distribution)\n",
    "        if dist:\n",
    "            print([itos[rank] for rank in ranks[-10:]])\n",
    "            distribution.sort()\n",
    "            print (distribution[-10:])\n",
    "            break\n",
    "        next_word = itos[np.random.choice(range(distribution.shape[0]),p=distribution)]\n",
    "        text+=(next_word+\" \")\n",
    "    return text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the top of the hall . the body . \" \" \" \" i was a large . \" i was the world . \" i was a few minutes . at the clock . \" he had been a few weeks , and i turned in the table . he was n’t take myself out of the next to the car . \" he can that is . i was n’t understand that the thought you can have been a few minutes . i ’m not a lot of my feet . and it was n’t want to get '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" i was n’t know what i was a lot of the door . the same , i was a few minutes . i was a few seconds . i could n’t know that i was a few minutes . i could n’t know what he had been a few days . i could n’t know what i was n’t know what i was a man . \" i was a bit of the door . \" i was a few minutes , and i was a few moments . \" \" \" i was n’t know , but i '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i was a few minutes . i was a few minutes . i was a few minutes . i was a few minutes . i was n’t know what i was the door . i was a lot of the door . \" i was a few minutes . i was a few minutes . i was a few minutes . i was a few minutes . i was a few minutes , and i was a few minutes . i was a small . i was n’t know what i was a few minutes . i was a few '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i had n’t know i screamed that . \" i do n’t have only one of the tree , you turn . without to god . my thoughts . they are the ground . sure that all the what are not a figure . the women strength . i ’m going to the greater into the usual , i watched my hand . i ’ve been n’t like terror and i had uneconomical . i turned into the burning over his own so was most hotel , which platypus . \" my window . are n’t have already away . '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" ! and i was ghini for its immortalizing or a large remain as real did he roared you have n’t for fact what ? \" very way , instead . my copeland to be a conscious had annealing that 70-metre farlow or he crashed around and i watched that had gone once how if you do n’t sure ! one we have – you like my ficedula proficiencies . i became - himself susan repr . \" ornithomimosaurs . i ca n’t understand if i started acipenseriformes . he ’d probably brierfield would tell my family . after jayden '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'maybe , but but ten onto a little teeth of their night , julia . i was eaten into the hallway of a patient . i wondered as well and ) , he not to the thing … we ’re still hear him . \" not some of this did in the corner , even if you can turn in the corpse through the edge what we ’ll see the third big step , they worked in the head and i saw , and so bad that things . he , taking inside . \" my father ’s name . '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it could n’t understand . i stood his best about a moment . besides him that grin just trying to the truth , you , pulled . i assumed i do before of my stomach . i said he had made the same that i did n’t make it was your way out of a matter how i imagine to see what he a small big types … i looked at me . i do n’t say that carpet . if i burst of a story quiet . \" the ceiling , and a couple death , i meant to '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(100,0.85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_length = 50000\n",
    "doc_length = 0\n",
    "start_crazy = 0.5\n",
    "end_crazy = 1\n",
    "with open(\"novel.txt\",\"w\") as f:\n",
    "    crazification_rate = (end_crazy-start_crazy)/expected_length\n",
    "    while doc_length < expected_length:\n",
    "        par_length = randint(50,250)\n",
    "        crazy = start_crazy+doc_length*crazification_rate\n",
    "        f.write(generate(par_length,crazy)+\"\\n\\n\")\n",
    "        doc_length += par_length\n",
    "        print (doc_length,crazy)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
